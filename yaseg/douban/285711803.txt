关于囚徒困境和自然选择的实验报告（未定稿）

在学习了 @ENT 老师的一文后，我决定把这个关于囚徒困境和自然选择的试验自己亲手做一遍。该实验的背景上文已有详述，我只择其要点重复一下：在面对囚徒困境时，人们可以设计出各种策略来应对，例如 ALLC（永远合作），ALLD（永远背叛），TFT（以牙还牙），WSLS（赢则继续输则改变），等等。试验中允许每个个体通过突变来选择策略，通过自然竞争来选择出最优的策略。由于这些策略是彼此相克的关系，在试验中可以观察到不同的策略先后占据统治地位。由于自然选择允许噪音，允许自由竞争，看起来比一对一的策略比赛更能刻画真实的社会演进状态。在我读完这篇文章之后，我首先想到的是这个试验的一个重要的局限性：这个策略空间是由实验设计者选定的一些策略组成的，它远远没有涵盖所有理论上可能采取的策略。因此，这个自然选择的环境是不完全的。确切来说，所谓策略，不外乎是说「在什么情况下以什么概率做某事。」也就是说，它是从「经验」到「行为」的一个随机函数。在这里「行为」事实上只有合作和背叛两种，所以这个随机变量可以被一个 [0, 1] 之间的实数完全刻划。假如它的值是 x，就表明以 x 为概率背叛对手而以 1-x 为概率同对手合作。而「经验」是一个离散集合，它包含两部分的信息：自己前一轮（或前几轮）的行为，以及对手前一轮（或前几轮）的行为。这些信息都是二值的（非此即彼）。因此，这是一个非常有限的集合。如果只用到上一轮的信息，这是一个只有 2^2 = 4 个元素的集合。从这个集合到 [0, 1] 区间的全体映射就构成了所有可能的策略，而前文中所列举的所有那些策略都只不过是这个策略空间中一些特例而已。因此，我们完全应当允许个体在这个真正意义上的「全体策略空间」中自然选择和进化，而不是只局限在那人为确定的几种可能性里。这个策略空间还可以进一步从使用前一轮的信息扩展到前 n 轮的信息。这样会让「经验」这个集合的大小指数上升（变成 4^n 个元素），但涵盖的策略就又会丰富得多。例如，一个人工智能程序可能会通过分析对手的前 n 步行为来推测其策略，从而制定自己相应的策略，这一人工智能程序本身可能极为复杂，但它所最终实现出的策略却也不过是我们的策略空间中的一个元素。也就是说，我们是在通过暴力的手段遍历所有可能存在的策略，而完全不用关心它是依据什么原理和逻辑设计出来的。因此，我们可以在此基础上模拟真正意义上的自然选择。以只采用前一步信息的策略为例，从一个包含 4 个元素的集合到 [0, 1] 区间中的映射不外乎是 4 维空间中的单位立方体中的一个点。我们可以让成员们在这个空间中随机地选择初始策略，让其充分竞争，然后依据优胜劣汰的原则进行选择，让获利最多的成员有最多的后代，并且允许成员们的后代的策略同其父辈的策略有随机的微小差异以促进进化。为此我写了一个程序来模拟这件事。种群的大小是个值得考量的因素，因为每个人都必须记住自己同其余所有人的博弈历史，因此计算复杂度是总人数的平方。为了节省运算时间，我只设定了一千个成员，这样可以保证每轮涵盖全体成员的博弈的总时间小于千分之一秒。每一万次全体博弈后进行一次演化，让最成功的个体产生最多的后代。统计一百代演化之后的结果。试验结果表明，原实验中所述的「坏人（ALLD）被以牙还牙的好人（TFT）大规模取代」这种情节在这个设定下很难发生。这是因为，原实验只有极有限的几种策略可供选择，因此，一个「坏人」要是突变，就只能一下子变成一个「好人」。而在这里的设定（在我看来也是更真实的设定）里，突变是连续性发生的，一个「坏人」更有可能突变成一个半好不坏的人（背叛的概率减少，合作的概率增加，但并不会一下子变成彻底的 TFT）。而这样的人并无太大的选择优势，很容易被淘汰。这个现象可以通过下面这张反映优胜者每次博弈的平均获利的图来展示。假定背叛者的获利是 3，彼此合作者的获利是 2，彼此背叛者的获利是 1，被背叛的合作者的获利是 0（这是最经典的囚徒困境的设定），所谓平均获利是说一个成员多次博弈后平均每次获得的利益。很显然，如果一个群体大多数人倾向于合作，平均获利应该接近 2，如果大多数人倾向于背叛，平均获利应该接近 1。下图展示了在进化中平均获利是如何迅速从 2 下降到 1 附近的。多次随机试验都得到了类似的结果，也就是说，进化的最终结果总是倾向于背叛的。这个结果是对初始条件相当不敏感的。即使通过人为强行设定让一定比例的人初始策略是 TFT（而其余随机选择策略），最后的结果也仍然会滑向背叛。只有当初始 TFT 的人数足够大（例如超过 10% ）时，最终 TFT 才能占据优势。这个临界比例的具体数值可以作为下一步试验的观察对象。这当然是非常令人失望（但也在意料之中）的结果。接下来的问题是：如果扩大试验人数和策略空间（把前一轮的信息扩充为前两轮甚至前三轮的信息），或者引入「声望」这个第三重变量，会有某种不倾向于背叛但又有进化优势的「神奇」策略出现么？